# mss-sepformer

This project aims to build a Music Source Separation (MSS) system using a Transfomer's encoder model called Separation Transformer (Sepformer). Sepformer has achieved a state-of-the-art performance on speech separation task compared to other deep learning models. Therefore, i would like to evaluate its performance on separating music sources. In this project, i use Sepformer model from SpeechBrain library as the separation module and MUSDB18 as the dataset, which is a dataset consists of full lengths music tracks along with its sources, which are vocals, bass, drums and others. For this project, the task is to separate a mixture of a song into four aforementioned sources.

This is an ongoing project. Therefore, this repository is subject to changes and any changes will be updated as soon as possible.
